#!/usr/bin/env python3
"""
Generated HarnessComponent
Auto-generated by V5.0 Two-Phase Generation Pipeline
"""

import asyncio
import logging
import time
import json
from typing import Dict, Any, Optional, List

# Import HarnessComponent base class
from evidence.phase6_harness.day1_harness_component.harness_component import HarnessComponent
from evidence.phase2_component_library.day1_core_component_classes.enhanced_base import ComponentConfiguration
import redis.asyncio as redis
import json


class Task_Store(HarnessComponent):
    """
    Generated task_store component
    
    Auto-generated by V5.0 Two-Phase Generation Pipeline
    Extends HarnessComponent for stream-based communication
    """


    def __init__(self, config: Dict[str, Any]):
        """Initialize task_store component"""
        component_config = ComponentConfiguration(
            name="task_store",
            service_type="task_store",
            **config
        )
        
        super().__init__(component_config)
        
        # Component-specific initialization
        self.config = config
        self.processing_stats = {
            "messages_processed": 0,
            "processing_time_total": 0.0,
            "errors_count": 0
        }
        
        self.logger.info(f"🔧 {self.name} (task_store) initialized")


    async def _initialize_component_resources(self):
        """Initialize component-specific resources"""
        self.logger.info(f"🔧 Initializing {self.name} resources")
        
        try:
            
        # Initialize stream error tracking
        self.stream_errors = {}
        
        # Initialize resource handles
        self.resource_handles = {}
        
        # Validate expected streams will be available
        self.expected_input_streams = ['input', 'store_commands']
        self.expected_output_streams = ['responses', 'store_data']
        
        # Initialize component state
        self.component_state = {
            "initialized": True,
            "initialization_time": time.time(),
            "status": "ready"
        }
            
            
        # Initialize storage backend
        storage_type = self.config.get('storage_type', 'memory')
        
        if storage_type == 'redis':
            # Setup Redis connection
            redis_config = {
                "host": self.config.get('redis_host', 'localhost'),
                "port": self.config.get('redis_port', 6379),
                "db": self.config.get('redis_db', 0)
            }
            self.redis_client = redis.Redis(**redis_config)
            self.resource_handles['redis'] = self.redis_client
            
        elif storage_type == 'memory':
            # Setup in-memory storage
            self.memory_store = {}
            
        else:
            raise ValueError(f"Unsupported storage type: {storage_type}")
        
        # Initialize storage metrics
        self.storage_metrics = {
            "operations_count": 0,
            "stored_items": 0,
            "retrieved_items": 0
        }
            
            
        # Initialize storage backend
        self.stored_tasks = {}
        self.storage_stats = {
            'total_operations': 0,
            'store_operations': 0,
            'retrieve_operations': 0
        }
            
            self.logger.info(f"✅ {self.name} resources initialized successfully")
            
        except Exception as e:
            self.logger.error(f"❌ {self.name} resource initialization failed: {e}")
            raise


    async def process(self):
        """Main processing loop with stream handling"""
        try:
            
            # Poll multiple input streams
            streams_checked = 0
            
                # Check input stream
                if 'input' in self.receive_streams:
                    try:
                        message = await self.receive_message('input', timeout=0.1)
                        if message is not None:
                            result = await self.process_message(message)
                            if result:
                                await self.send_result(result)
                    except Exception as e:
                        await self.handle_stream_error('input', e)

                # Check store_commands stream
                if 'store_commands' in self.receive_streams:
                    try:
                        message = await self.receive_message('store_commands', timeout=0.1)
                        if message is not None:
                            result = await self.process_message(message)
                            if result:
                                await self.send_result(result)
                    except Exception as e:
                        await self.handle_stream_error('store_commands', e)
            
            # Brief pause if no messages processed
            if streams_checked == 0:
                await asyncio.sleep(0.01)
            
        except Exception as e:
            self.logger.error(f"❌ Processing error in {self.name}: {e}")
            await self.handle_processing_error(e)
    
    async def process_message(self, message_data: Any) -> Optional[Dict[str, Any]]:
        """Process individual message"""
        start_time = time.time()
        
        try:
            # Business logic processing
            result = await self.execute_storage_operation(message_data)
            
            # Update statistics
            processing_time = time.time() - start_time
            self.processing_stats["messages_processed"] += 1
            self.processing_stats["processing_time_total"] += processing_time
            
            return result
            
        except Exception as e:
            self.processing_stats["errors_count"] += 1
            self.logger.error(f"❌ Message processing error: {e}")
            raise
    
    async def send_result(self, result: Dict[str, Any]):
        """Send processing result to appropriate output streams"""
        
        # Send to responses stream
        if 'responses' in self.send_streams:
            try:
                await self.send_message('responses', result)
                self.logger.debug(f"✅ Sent result to responses")
            except Exception as e:
                self.logger.error(f"❌ Failed to send to responses: {e}")

        # Send to store_data stream
        if 'store_data' in self.send_streams:
            try:
                await self.send_message('store_data', result)
                self.logger.debug(f"✅ Sent result to store_data")
            except Exception as e:
                self.logger.error(f"❌ Failed to send to store_data: {e}")
    
    async def handle_processing_error(self, error: Exception):
        """Handle processing errors with recovery"""
        self.logger.warning(f"⚠️ Handling processing error: {error}")
        
        # Error recovery logic
        await asyncio.sleep(0.1)  # Brief pause before retry


    async def _cleanup_component_resources(self):
        """Clean up component-specific resources"""
        self.logger.info(f"🧹 Cleaning up {self.name} resources")
        
        try:
            
            # Cleanup storage connections
            if hasattr(self, 'redis_client'):
                try:
                    await self.redis_client.close()
                except:
                    pass
            
            # Clear memory storage
            if hasattr(self, 'memory_store'):
                self.memory_store.clear()
            
            
        # Log storage statistics
        self.logger.info(f"Storage stats: {self.storage_stats}")
        if hasattr(self, 'stored_tasks'):
            self.logger.info(f"Final task count: {len(self.stored_tasks)}")
            
            # Close any remaining resources
            if hasattr(self, 'resource_handles'):
                for handle_name, handle in self.resource_handles.items():
                    try:
                        if hasattr(handle, 'close'):
                            await handle.close()
                        elif hasattr(handle, 'disconnect'):
                            await handle.disconnect()
                        self.logger.debug(f"✅ Closed {handle_name}")
                    except Exception as e:
                        self.logger.warning(f"⚠️ Error closing {handle_name}: {e}")
            
            self.logger.info(f"✅ {self.name} cleanup completed")
            
        except Exception as e:
            self.logger.error(f"❌ {self.name} cleanup failed: {e}")
            # Don't re-raise cleanup errors


    async def execute_storage_operation(self, data: Any) -> Dict[str, Any]:
        """
        Execute storage operations on tasks
        Generated from ComponentLogic definition
        """
        try:
            # Business logic implementation
            
            operation = data.get('operation', 'unknown')
            
            if operation == 'store_task':
                # Store task data
                task_data = data.get('data', {})
                task_id = task_data.get('id', 'unknown')
                
                # Simulate storage (in production would use Redis/DB)
                if not hasattr(self, 'stored_tasks'):
                    self.stored_tasks = {}
                
                self.stored_tasks[task_id] = task_data
                
                result = {
                    'status': 'stored',
                    'data': {'id': task_id, 'stored_at': time.time()}
                }
                
            elif operation == 'retrieve_tasks':
                # Retrieve tasks
                query = data.get('data', {})
                
                if not hasattr(self, 'stored_tasks'):
                    self.stored_tasks = {}
                
                # Simple retrieval (in production would query DB)
                tasks = list(self.stored_tasks.values())
                
                result = {
                    'status': 'retrieved',
                    'data': tasks
                }
                
            else:
                result = {
                    'status': 'error',
                    'message': f'Unknown storage operation: {operation}'
                }
            
            return result
            
        except Exception as e:
            self.logger.error(f"❌ Business method execute_storage_operation error: {e}")
            raise


    async def handle_stream_error(self, stream_name: str, error: Exception):
        """Handle stream operation errors"""
        self.logger.warning(f"⚠️ Stream error on {stream_name}: {error}")
        
        # Record error for monitoring
        if not hasattr(self, 'stream_errors'):
            self.stream_errors = {}
        
        if stream_name not in self.stream_errors:
            self.stream_errors[stream_name] = 0
        
        self.stream_errors[stream_name] += 1
        
        # Exponential backoff for repeated errors
        if self.stream_errors[stream_name] > 3:
            await asyncio.sleep(min(2.0 ** (self.stream_errors[stream_name] - 3), 30.0))

    def get_stream_status(self) -> Dict[str, Any]:
        """Get status of all component streams"""
        status = {
            "input_streams": {},
            "output_streams": {},
            "stream_errors": getattr(self, 'stream_errors', {})
        }
        
        # Check input streams
        for stream_name in ['input', 'store_commands']:
            if stream_name in self.receive_streams:
                connection = self.receive_streams[stream_name]
                status["input_streams"][stream_name] = {
                    "connected": True,
                    "message_count": connection.message_count,
                    "last_activity": connection.last_activity
                }
            else:
                status["input_streams"][stream_name] = {"connected": False}
        
        # Check output streams  
        for stream_name in ['responses', 'store_data']:
            if stream_name in self.send_streams:
                connection = self.send_streams[stream_name]
                status["output_streams"][stream_name] = {
                    "connected": True,
                    "message_count": connection.message_count,
                    "last_activity": connection.last_activity
                }
            else:
                status["output_streams"][stream_name] = {"connected": False}
                
        return status

    async def send_to_multiple_streams(self, data: Dict[str, Any], stream_names: List[str] = None):
        """Send data to multiple output streams"""
        target_streams = stream_names or ['responses', 'store_data']
        
        results = {}
        for stream_name in target_streams:
            try:
                success = await self.send_message(stream_name, data)
                results[stream_name] = success
            except Exception as e:
                results[stream_name] = False
                self.logger.error(f"❌ Failed to send to {stream_name}: {e}")
        
        return results

    async def check_stream_connectivity(self) -> Dict[str, bool]:
        """Check connectivity of all streams"""
        connectivity = {}
        
        # Check input streams
        for stream_name, connection in self.receive_streams.items():
            try:
                # Simple connectivity check - stream should not be closed
                connectivity[f"input_{stream_name}"] = not connection.stream._closed
            except:
                connectivity[f"input_{stream_name}"] = False
        
        # Check output streams
        for stream_name, connection in self.send_streams.items():
            try:
                connectivity[f"output_{stream_name}"] = not connection.stream._closed
            except:
                connectivity[f"output_{stream_name}"] = False
        
        return connectivity

    def get_stream_metrics(self) -> Dict[str, Any]:
        """Collect stream performance metrics"""
        metrics = {
            "total_input_streams": len(self.receive_streams),
            "total_output_streams": len(self.send_streams),
            "total_messages_received": 0,
            "total_messages_sent": 0,
            "stream_errors": sum(getattr(self, 'stream_errors', {}).values()),
            "stream_details": {}
        }
        
        # Input stream metrics
        for stream_name, connection in self.receive_streams.items():
            metrics["total_messages_received"] += connection.message_count
            metrics["stream_details"][f"input_{stream_name}"] = {
                "messages": connection.message_count,
                "last_activity": connection.last_activity,
                "buffer_size": connection.buffer_size
            }
        
        # Output stream metrics
        for stream_name, connection in self.send_streams.items():
            metrics["total_messages_sent"] += connection.message_count
            metrics["stream_details"][f"output_{stream_name}"] = {
                "messages": connection.message_count,
                "last_activity": connection.last_activity,
                "buffer_size": connection.buffer_size
            }
        
        return metrics