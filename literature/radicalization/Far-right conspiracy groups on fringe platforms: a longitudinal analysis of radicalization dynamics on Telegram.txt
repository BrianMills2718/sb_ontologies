ConvergenceVolume 28, Issue 4, August 2022, Pages 1103-1126
© The Author(s) 2022
, Article Reuse Guidelines
https://doi.org/10.1177/13548565221104977
Logo
Creative Commons License (CC BY-NC 4.0)
Special Issue: Conspiracy Theories in Digital Environments
Far-right conspiracy groups on fringe platforms: a longitudinal analysis of radicalization dynamics on Telegram
Heidi Schulzehttps://orcid.org/0000-0003-0079-91691, Julian Hohner2, Simon Greiplhttps://orcid.org/0000-0002-5652-88893, Maximilian Girgnhuber4, Isabell Desta5, and Diana Riegerhttps://orcid.org/0000-0002-2417-04806
Abstract
Societal crises, such as the COVID-19 pandemic, produce societal instability and create a fertile ground for radicalization. Extremists exploit such crises by distributing disinformation to amplify uncertainty and distrust among the public. Based on these developments, this study presents a longitudinal analysis of far-right communication on fringe platforms, demonstrating radicalization dynamics. Public Telegram communication of three movements active in Germany (QAnon, Identitarian Movement, Querdenken) was analyzed through a quantitative content analysis of 4500 messages posted to nine channels between March 2020 and February 2021. We study the movements' discourse using several indicators of radicalization dynamics. The increasing prevalence of conspiracy narratives, anti-elitism, political activism, and support for violence indicate radicalization dynamics in these movements’ online communication. However, these dynamics varied within the movements. It can be concluded that, when studying radicalization dynamics online, it is crucial to not just focus on one single indicator, but consider longitudinal changes across several indicators, ideally comparing different movements.
Keywords
COVID-19, conspiracy theories, fringe platforms, identitarian movement, political activism, Querdenken, QAnon, telegram, radicalization
1Department of Media and Communication, Ludwig Maximilian University of Munich, Munich, Germany
2Department of Media and Communication, Ludwig Maximilian University of Munich, Munich, Germany
3Department of Media and Communication, Ludwig Maximilian University of Munich, Munich, Germany
4Department of Media and Communication, Ludwig Maximilian University of Munich, Munich, Germany
5Department of Media and Communication, Ludwig Maximilian University of Munich, Munich, Germany
6Department of Media and Communication, Ludwig Maximilian University of Munich, Munich, Germany
Corresponding author(s):
Heidi Schulze, Department of Media and Communication, Ludwig Maximilian University of Munich, Oettingenstraße 67, Munich, 80538, Germany. Email: heidi.schulze@lmu.de
Introduction
Societal crises give rise to societal instability and create a fertile ground for radicalization and extremism (Funke et al., 2016). The global COVID-19 pandemic is one example of this effect. The increasing number of demonstrations and protest movements in 2020 proves a growing discontent with political decision-making. Extremists tap into such crises by distributing disinformation and conspiracy narratives to amplify feelings of uncertainty and distrust among the public. Previous studies of pandemic-related, politically biased news content confirm this by showing that extremist actors distribute content that ‘contribute[s] to a contradictory, menacing, and distrusting worldview’ (Boberg et al., 2020: 1). Specifically, violent far-right1 actors increased their online activities following the announcement of the pandemic (Davies et al., 2021). People with a sense of uncertainty and existential fear are more receptive to radical voices and conspiratorial thinking (Rieger et al., 2017). The consequences of these developments became apparent when demonstrations began to be accompanied by aggressive and violent behavior. Public security institutions suggested that protest groups present high levels of extremism, possibly posing a threat to the democratic order.
At the same time, public pressure on social media companies is growing to decrease the influence and reach of extremist actors. Social media companies responded to these developments by deleting videos and accounts of alleged extremist protest groups. As a consequence of extensive account removals, protest groups and far-right actors increasingly rely on fringe platforms for undisturbed communication within their communities (Rogers, 2020). Additionally, in times of reduced physical contact, the relevance of online communication increases. In 2020, specifically, the instant messaging platform Telegram became the center of public discourse on COVID-19-related conspiracy narratives, far-right movements, and protest groups (Reichardt, 2021). Telegram supposedly not only served as a platform to organize protests (Holzer, 2021) but is also considered a facilitator of radicalization dynamics and the spread of conspiracy narratives (Garry et al., 2021; Hohlfeld et al., 2021).
While online communication is relevant in all radicalization processes, most studies of radical or extremist online communication predominantly focus on Islamist radicalization and present a static snapshot (Rothut et al., 2022). However, the term radicalization indicates a process which should be studied by analyzing changes in online (extremist) communication over time.
This paper advances previous research by (1) focusing on far-right online communication, (2) employing a longitudinal design, (3) studying several content factors as indicators of radicalization dynamics, and (4) giving insights into the strategic online communication of extremist movements. Specifically, we aim to determine whether indications of radicalization dynamics occur in far-right discourse on fringe platforms. To address this research question, we analyzed the public Telegram communication of three far-right movements in Germany by performing a quantitative content analysis of messages posted on Telegram over the course of one year. Germany was chosen as a use case primarily for two reasons: Germany was the first country to introduce a law (‘NetzDG’) that forces platform companies to strictly moderate content, which is why far-right movements rely more on fringe platforms than in other countries; Germany was one of the first countries to be confronted with highly organized movements protesting COVID–19-containing measures, and these protests were strategically subverted by radical, extremist, and conspiracy actors and grew more radical and violent throughout the pandemic (Barker, 2020). This study concentrated on radical/extremist movements explicitly rooted in conspiracy narratives surrounding COVID-19. As indicators of radicalization dynamics, we studied changes in the prevalence of conspiracy narratives, anti-elitism, political participation and activism and violence on nine Telegram channels of three far-right movements.
Radicalization (online)
The definitions and operationalizations of radicalization vary and are usually directly oriented to epistemological interest and the respective scholarship. Models that conceptualize radicalization are partly contradictory and are subject to continuous debate (for an overview, see e.g., Dzhekova et al., 2016). The only aspect that unites all definitions concerns the process character, that is, radicalization as a development that is not necessarily linear but can also unfold in non-linear dynamic instances.
This paper follows the definition of Abay Gaspar et al. (2020), who defined radicalization as ‘the increasing challenge to the legitimacy of a normative order and/or the increasing willingness to fight the institutional structure of this order’ (p. 5). This definition links radicalization to violent action – as in most definitions – but does not consider this the only possible outcome or necessary prerequisite for increasing radicalization. Referring to a normative order, the definition also emphasizes a situative characteristic, indicating whether radicalization occurs and at what rapidity is highly context-dependent.
The term online radicalization is even more contested because radicalization dynamics are rooted in, or at least linked to, offline developments and grievances (Odağ et al., 2019). However, it is generally agreed that in today’s media environment, radicalization is a complex reciprocal process that unfolds from a mixture of online and offline communication and interactions (Gaudette et al., 2020; Mølmen and Ravndal, 2021). These dynamics are highly complex and, thus, difficult to address based on empirical research. Some studies have approached this challenge by interviewing imprisoned (Baugut and Neumann, 2020) or former extremists (Gaudette et al., 2020) to gain insights into the relevance of online communication for radicalization processes. While these studies often emphasize the important role of the internet, they cannot typically account for user-specific differences in online behavior and provide only superficial conclusions on online communication.
To close this gap, we focus on how radicalization dynamics2 unfold in online environments. Many studies have been concerned with the presence of extremist content online, either on specific websites (Scrivens, 2020), social media (Ahmed et al., 2020), or fringe platforms (Hine et al., 2017). However, these studies neither account for discourse radicalization as a process nor conceptualize specific indicators. The limited studies accounting for temporal dynamics examine activity as an explanatory variable but neglect content-specific changes in communication (e.g., Walther and McCoy, 2021). In this paper, we argue that necessary prerequisites or indicators of a radicalization process, especially in the case of radicalization dynamics in online environments, can be approached by measuring the changes in the prevalence of certain themes. Specifically, we argue for the relevance of considering conspiracy narratives, anti-elitism, political activism as well as support for violence.3
To the best of our knowledge, so far only one paper has studied indicators of radicalization dynamics in social media posts by employing a longitudinal design. Riebe et al. (2018) studied group communication in a Facebook group of a radical right party and focused on the changes in language linked to specific narratives. They observed an increase in several indicators (e.g., racism, anti-elitism) evaluating the approach as well-suited to study radicalization dynamics. Although they included indicators that address far-right ideology and anti-elitism, other aspects, traditionally considered part of far-right ideology (e.g., Mudde, 2002), are missing. Finally, the authors specifically stress the relevance of conspiracy narratives for analyzing radicalization dynamics.
How conspiracy theories relate to radicalization
The term ‘conspiracy’ refers to the secret cooperation of two or more actors whose actions aim to influence events in their favor. Consequently, conspiracy narratives can be understood as an attempt to explain the occurrence of events on the suspicion that influential institutions, groups, or individuals are joining forces in secret to achieve a goal for their benefit that is perceived as insidious (Popper, 2003). ‘Such conspiracies typically consist of either powerful others (e.g., politicians, CEOs, scientists) or marginalized groups (e.g., Muslims, Jews)’ (Van Prooijen et al., 2015: 571) and offer alternative explanations that deviate from the usual explanatory patterns. Conspiracy narratives are frequently considered an expression of a defensive position against current political representatives and democracy itself (Pickel et al., 2020: 106). Most conspiracy narratives are extremist at their core, and all extremist ideologies have an underlying conspiracy narrative (Van Prooijen et al., 2015).
While people differ in their susceptibility to conspiracy narratives, those who believe one conspiracy narrative are more likely to support others as well (Goertzel, 1994). Social psychology refers to this as conspiracy mentality, which is ‘the individual tendency to perceive the world as a place full of conspiracies’ (Lamberty, 2020a: 2). People with a pronounced conspiracy mentality show higher levels of distrust in democracy and are more likely to support violence as a means to achieve political interests (Pickel et al., 2020). A high sense of uncertainty and the feeling of having no control over the current situation are particularly important drivers of belief in conspiracy narratives (Whitson and Galinsky, 2008). To deal with this perceived loss of control, people turn to conspiracy narratives that offer simple explanations for complex, threatening developments (Imhoff and Lamberty, 2020). Similarly, perceived threats and individual insecurities promote increased support for one’s own (extremist) ideology, thus contributing to radicalization processes (McGregor et al., 2013). Crises and pandemics inevitably support feelings of insecurity and loss of control – both on a societal and individual level. Therefore, it is not surprising that the topic of conspiracy narratives is highly present in public discourse relating to the COVID-19 pandemic.
In particular, social media are accused of contributing greatly to the spread of conspiracy narratives by creating the ideal opportunity structures for emergence, dissemination, and acceleration (Pickel et al., 2020). Various studies indicate that in the wake of societally important events, such as large protests or terrorist attacks, the spread of conspiracy narratives on social media increases greatly due to lacking information or ideology-based communication (Douglas et al., 2019; Starbird, 2017). In the course of the COVID-19-related protest movements, various conspiracy narratives were spread in fringe platforms (Zeng and Schäfer, 2021), from there moving to news coverage and ultimately becoming part of the public discourse (Shahsavari et al., 2020).
The extent to which social media intensifies conspiracy beliefs or increases conspiracy supporters in the long term has not yet been empirically investigated. However, presuming that any contact with conspiracy-related content promotes mistrust and skepticism in society, a positive correlation is suspected (Imhoff and Lamberty, 2020). In line with an assumed amplification effect, research shows that a higher level of conspiracy mentality can generate more contact with conspiracy narratives (Stieger et al., 2013). It is therefore important to consider the (increasing) presence of conspiracy narratives that sets off a development of reinforcing skepticism and distrust in the ‘mainstream’ explanation and the (political) actors who represent these opinions. These anti-democratic resentments in combination with extremist beliefs are indicating radicalization dynamics as described before.
Fringe platforms as facilitators of extremism
In general, the term social media platform is an umbrella term. It describes digital offerings that are based on digital networking technologies and enable information access and sharing to establish or maintain social relationships (Taddicken and Schmidt, 2017). Due to the increasing variety of social media platforms, the traditional large platforms, such as Facebook or YouTube, are often referred to as ‘mainstream platforms' in contrast to ‘fringe platforms' (e.g., Van Dijck et al., 2021).
Fringe platforms are known to be the origin of some conspiracy movements. Specifically, for COVID–19-related conspiracy narratives, fringe platforms function as a source and breeding ground (Shahsavari et al., 2020). Although the number of papers studying fringe platforms is increasing, there is no common definition of the term.4 We understand fringe in relation to political extremism and consider ‘fringe platforms’ as social media platforms that were either built to facilitate extremist communication or do so by design and that are used by fringe communities or radical/extremist actors out of necessity, accepting a limited reach in favor of undisturbed discourse. Therefore, the term ‘fringe platform’ is also an umbrella term and can refer to various platforms with different digital architectures and features that result in different affordances, possibly facilitating radicalization (for a theoretical discussion of features/affordances facilitating radicalism (see Schulze et al., 2022 or Frischlich et al., 2022). The central common denominator of fringe platforms is the lack or at least the flexible application of moderation policies: Fringe platforms rarely/never moderate or delete extremist content, either under the pretense of uncensored opinion exchange or to support less regulated, anonymous communication (Jasser et al., 2021).
Fringe platforms may facilitate radicalization dynamics in several ways. The high prevalence of extremist content can support radicalization dynamics by decreasing empathy with the outgroup and desensitizing derogatory language on the societal level (Bilewicz and Soral, 2020). Compared to ‘mainstream’ social media platforms, fringe platforms are used by a limited number of users for greater coherence of ideas and attitudes. Users tend to prefer online environments that provide opinion-consistent information and groups that present greater familiarity (Edgerly and Vraga, 2020). In environments in which opinions are more homogeneous, echo-chamber effects can facilitate the reinforcement of radical, and to some extent hateful, attitudes that often remain uncontradicted. The more often internet users participate in discussions in a homogeneous, extreme online forum, the more radical their statements can become (Wojcieszak, 2009). Deplatforming from large social media platforms can strengthen the ingroup’s cohesion. Furthermore, most fringe platforms support anonymous communication, which makes them more attractive for extremist actors and promotes more radical thoughts and environments (Gaudette et al., 2020).
Telegram as a fringe platform
In 2020, the instant messenger Telegram became the subject of public discourse and concern in the context of COVID–19-related conspiracy narratives and far-right movements. There was an open debate about the opportunity structures of Telegram for radicalization and extremist communication in relation to growing ‘covid-skepticism’ and protest activism (e.g., Hunger et al., 2021). However, even before the pandemic, the US far-right had called for a platform migration from Discord to Telegram in 2016. Telegram presents itself as a platform for open, uncensored, and anonymous communication and rarely deletes extremist content.
Over the past years, extremist actors have recognized the advantages of instant messengers and increasingly employ them for strategic communication, mobilization, and/or information dissemination. From the perspective of extremist actors, Telegram offers the ideal digital communication environment because all activities can be organized via the same platform. Telegram is considered a fringe medium because it facilitates the distribution of propaganda and recruitment of new activists via (semi-)public channels, in which only the administrators can publish, while at the same time and within the same communication environment, (closed) groups and private chats support the planning of activities, including (terrorist) attacks. Still, extremists also rely on large social media platforms as means of ideology amplification into wider discourses, as well as for recruitment of new supporters, dissemination of propaganda, and as sources for financing. On Telegram, this is visible because many posts link to ‘mainstream’ platforms but also disproportionately to alternative and hyperpartisan news websites (Holzer, 2021; Schulze, 2021). To some extent, Telegram serves as a means to collect and disseminate information from and across several networks and platforms and is therefore used to effectively increase the reach of content.
Despite the high relevance of Telegram for extremist communication, there are relatively few studies addressing far-right communication on Telegram, although the presence of far-right channels increased greatly following deplatforming activities by large platforms (Schulze, 2021; Urman and Katz, 2020). However, most far-right channels are only loosely connected, especially across nationality and ideological characteristics (Urman and Katz, 2020).
Regarding the specific content, the saliency of conspiracy narratives is greater on Telegram than on Facebook (Hohlfeld et al., 2021), making it a primary platform for the digital organization of COVID–19-related protests in Germany (Holzer, 2021). COVID–19-related communication functions as driver of conspiracy narratives (Walther and McCoy, 2021), in which elites and governments are criticized, and discontent with the existing political system/the government is voiced. These themes mobilize distrust and facilitate the distribution of conspiracy narratives and radical and extreme positions (Holzer, 2021).
While previous studies have shown a high prevalence of conspiracy narratives and radical/extremist content, none have used a longitudinal approach to study the temporal development of far-right communication within Telegram. Thus, we pose the following research question:

    Does discourse in far-Right Telegram channels indicate radicalization dynamics?

Indicators of radicalization dynamics
Whether and to what extent discourses become radicalized on social media can be studied with respect to (the growing prevalence of) several indicators. Of course, following the discussed link of conspiracy narratives and radicalization, the prevalence of conspiracy narratives is to be considered as a relevant indicator.
In addition, anti-elitism has been shown to be a relevant indicator (Riebe et al., 2018). An increasing presence of anti-elite expressions can be considered an indication of ‘the increasing challenge to the legitimacy of a normative order’ (Abay Gaspar et al., 2020: 5), as outlined in the definition of radicalization. Anti-elitism as a concept is a central part of far-right ideology (Mudde and Kaltwasser, 2017). By voicing critique toward actors perceived to be part of the elite (e.g., leading politicians, government, or journalistic institutions), the far right cleaves between ordinary people and the political opponents. Radical right actors have been shown to employ anti-elite sentiment strategically to incite people against the status quo and political elites (Ernst et al., 2017), to mobilize voters (Aslanidis, 2018), and to continuously increase discontent with the normative order (Gidron and Hall, 2020). This might foster resentments through feelings of anger or fear, possibly mobilizing people for political action.
Furthermore, as a relevant indication of a growing intention to act upon rising resentment with the political system, we consider increasing calls for and expressions of political participation and activism as an expression of the ‘increasing willingness to fight the institutional structure of this order’ (Abay Gaspar et al., 2021: 5). For example, increasing protest activity can be considered a consequence of growing discontent, and ‘protest activity and extremism are interdependent manifestations’ (Agapov et al., 2020: 480). Today, social media plays a central role in activism, especially in mobilization for action, and both offline and online participation can be linked to activism (Harlow and Harp, 2012). Radicalization is not necessarily linked to violent action, and many political activists remain non-violent when challenging the normative order, despite increasing offline and online activism. An increase in calls for political participation and activism is thus an indicator of a rising resentment towards the political system in general.
Although radicalization dynamics do not necessarily result in violent behavior, violent action is considered its strongest expression. Expressions of support for violence are more likely to be present in more radicalized and conspiracy-related contexts and can be considered a manifestation of extremist tendencies (Pickel et al., 2020). The individual inclination to use violence is a legitimate tool for changing the status quo while also violating the democratic order (Leader Maynard and Benesch, 2016). Compared to offline violence, expressions of support for violence are more prevalent in online environments (Struck et al., 2017). Furthermore, violent events offline can be linked to the support of violence online (Oltenau et al., 2018). Similar to increasing political activism, increasing calls for violence are an indicator of radicalization dynamics on the discourse level but should be differentiated regarding their severity and addressee.
Presumably, there are far more indicators of discourse radicalization dynamics; however, the described ones seem to function as a useful translation of our underlying definition of radicalization, supporting our aim of researching conspiracy-related far-right movements. Hence, we expand our research question and ask whether the discourse in far-right Telegram channels indicates radicalization dynamics reflected by an increasing prevalence of conspiracy narratives, anti-elitism, calls for political participation and activism and support for violence.
Methods
We compared three different radical, and to some extent, extremist, movements linked to one or several conspiracy narratives. To study the movements’ public Telegram communication, we conducted a quantitative content analysis. A longitudinal research design allows to account for temporal dynamics. We observed communication over the course of one year, from 01 March 2020 to 28 February 2021. The starting point was chosen because this date approximately marked the time that COVID-19 was spreading in Europe, although it was not ruled a pandemic until 11 March, following which governments slowly started to implement regulations to slow the spread.
Movement and channel selection
The selection of far-right movements poses a challenge for most research in far-right communication because of the heterogeneity and volatility of right-wing radical or extremist actors (Berntzen, 2019; Bjørgo and Ravndal, 2019; see Endnote 1) as well as their online discourses (Vollmer and Karakayali, 2018). This paper focused on the communication of several digitally highly active and outspoken (far-right) movements. The Identitarian Movement (IM) was chosen as a well-known far-right extremist movement, fundamentally built on the conspiracy narrative of the ‘Great Replacement’, which claims that elites secretly plan to replace the ‘white’ population in Western countries with Muslims (Obaidi et al., 2021). As a second group, QAnon, also known as a ‘meta-conspiratorial narrative’ (Mahl et al., 2021: 4), was selected because it is deeply rooted in a variety of conspiracy narratives and, over time, has evolved into a highly extremist violent movement considered a threat to national democratic institutions. Finally, as a third group, Querdenken (transl. to ‘lateral thinking’) was included as a protest movement that formed in reaction to COVID–19-related regulations; it allegedly radicalized to an extremist movement throughout 2020 and is officially under observation by Germany’s Federal Office for the Protection of the Constitution. Querdenken’s communication on Telegram is directly linked to influential far-right actors (Holzer, 2021) but is the least extreme and conspiratorial movement of the three studied here.
For each movement, three exemplary Telegram channels were selected. The channel selection was challenged by the great differences in the channels’ communication frequency (see Table 1) as well as the heterogeneity of the movements’ channels. Several steps were involved in this selection process. In addition, we created a list of Telegram channels for each movement via snowball sampling. Ultimately, the channels were selected on the basis of the following criteria: German language, high reach (number of followers and post view counts), number of posts and channel activity during the research period. Concerning relevant QAnon and IM actors and their Telegram communication, previous analyses were consulted (Dittrich et al., 2020; Fielitz and Schwarz, 2020). Channel selection for Querdenken was more difficult. As a movement that evolved following COVID-19 regulations, the earliest Querdenken channels began in April 2020 and do not cover the entire sample period. We chose two channels that were the earliest to be active and had the most followers and one channel that started later but, in addition to its high reach, presented the highest activity during the sampling period.
Data collection
All publicly available Telegram posts from these nine channels (three per movement) – including text and metadata, excluding multimedia content – were collected using two approaches: (1) via Python and the Telethon library (Lonami, 2019) and (2) the software suite 4CAT, both relying on the Telegram API (Peeters and Hagen, 2018; Telegram FZ-LLC, 2020). Several instances of data collection (Jul., Oct., Dec. 2020, Jun. 2021) were assumed to minimize missing data due to deletion by channel administrators. Based on continuous Post IDs, it can be estimated that overall, 4406 entries (one Telegram post can consist of several entries) were deleted prior to data collection and could not be considered in the analysis. Data preprocessing and sampling were performed using Python. In preprocessing, all posts not containing text or consisting only of punctuation marks or URLs were deleted, resulting in a sample size of ∼38 Tsd Telegram messages.
Sampling
Posting activity across movements and channels varied greatly. QAnon channels posted ten times more than the other two movements (Table 1). To level the influence of the movements while accounting for the channels’ activity and reducing the influence of times of high posting frequency to support the longitudinal design, the random sample was not simply drawn from the overall sample but based on the following selection criteria: 1500 posts per movement with the percentage of posts per channel reflecting the channel’s activity and a random selection of a fixed number of posts per week (53 weeks in the sample) per channel based on the channels’ activity over the year. An additional random sample supplemented missing messages resulting from insufficient posting activity and rounding errors. From the remaining posts, 100 messages per movement, 300 posts altogether, were randomly selected to pretest the codebook.
Three authors were involved in the coding process. The pretest presented satisfactory intercoder reliability for content-related variables: Holsti ranged from 0.8 to 1.0 for aggregate-level variables. Although Krippendorff’s alpha is often preferred, Holsti was used in this case because it is the best-suited measure for nominally binary-scaled variables (Feng, 2014), and Krippendorff’s alpha is shown to be less robust when assessing rarely occurring categories (Quarfoot and Levine, 2016). Pretest and data analysis were performed in R/RStudio with the packages tidycomm (Unkel, 2021) and tidyverse (Wickham et al., 2019). Trend analyses were performed using R’s funtimes package (Lyubchich et al., 2021), which implements robust nonparametric difference-based estimators and bootstrap techniques to test hypotheses regarding possible (non-)linear trends in the data. Presuming that the time series may be autocorrelated, linear trend analysis employed a sieve-bootstrap approach of the t-test (see Noguchi et al., 2011) and an autoregressive filter selected by the Bayesian information criterion (BIC). The test for any trend, possibly non-monotonic, uses the local regression-based WAVK test, also based on sieve-bootstrap (see Lyubchich et al., 2013). A p-value below 0.05 indicated a significant trend in the data. The code and supplementary materials were uploaded to an OSF repository.5
Table 1 presents an overview of the data processing and sample selection steps. Data preparation indicated that most Telegram posts were rather short and frequently referred to recent political events, often without clearly referencing the specific events. Therefore, a post, its attachments (e.g., URLs, videos, photos), and its context, which can be accessed through a unique URL provided by Telegram, were assessed together. Despite careful preprocessing, 362 posts could not be considered in the full coding procedure because they were too short to present any meaning, or they were deleted, making the context undefinable. The final sample for further analyses consisted of 4118 posts.
Content categories
Conspiracy narrativesThis category measured the presence of conspiracy narratives in a post. There is no comprehensive and/or distinctive list of existing conspiracy narratives since they constantly evolve and overlap. Thus, this category was designed hierarchically and clustered 20 conspiracy narratives in three overarching types of conspiracy narratives: General (e.g., Flat Earth), Specific Far-right (e.g., Great Replacement), and COVID–19-specific narratives (e.g., Vaccination for Chip Implantation). A list of the most prevalent conspiracy narratives was derived from previous research (e.g., Mahl et al., 2021; Zeng and Schäfer, 2021).
Far-right ideologyThe movements included in the analysis are said to present patterns of radical or extremist ideology, though the movements themselves sometimes refute these claims. This category measured far-right themes based on six variables following Carter (2018: 175), who considers ‘authoritarianism, [...] anti-democracy, and [...] nationalism defining properties of right-wing extremism/radicalism’ and ‘xenophobia, racism, and populism’ as ‘accompanying characteristics’. The definitions of each variable presented in the codebook were developed by Mudde (2002: 187–189) and Hawkins et al. (2018).
Anti-elitismThis measure indicated the presence of anti-elite sentiment for specific groups. We differentiated seven groups: politicians, ‘mainstream’ parties, and government; political opponents, the left (QAnon usually refers to the liberal elite and not the Trump government); ‘mainstream’ news media; public broadcasting system; science, scientists, university, and research; police and security organizations, and (social media) companies.
Political participation and activismThis category measures the level of activism, indicating whether a post contains one or several calls for actions to mobilize online or offline participation. Several (offline/online) political participation scales were consulted, but many traditional items (e.g., voting) do not fit the extremist context or apply to content analyses. Finally, we included items from Casemajor et al. (2015), Theocharis et al. (2021), and Wojcieszak (2009), deriving a hierarchical list of 20 items within the overarching categories of online activism (e.g., social media engagement), offline activism (e.g., participation in demonstrations), and online/offline activism (e.g., recruitment of new members).
ViolenceThis category indicated support for or rejection of violence based on Gerstenfeld et al. (2003) and Struck et al. (2017). We distinguished six affirmations of violence, indicating support for violent actions: approval of violence, propensity for violence, personal use of violence, call for armament, and explicit and implicit calls for violence. Three items indicated negative stances towards violence, expressing the rejection of violent behavior: personal demarcation of violence, condemnation of violence, and condemnation of violence against far-right actors.
Results
The following section will first present the results concerning the presence of far-right ideology before describing the results of the time series analyses concerning the prevalence of conspiracy narratives, anti-elitism, activism and participation, and violence.
Concerning the presence of far-right ideology, about a third (33%) of all posts contained some characteristic of far-right ideology, mostly explained by populism (26%) and xenophobia (9%). The group-specific analysis yields great differences: the Identitarian Movement’s posts had the highest presence of far-right references, with 40% of their posts referencing at least one indicator. Far-right themes were slightly less present in the communication of QAnon (36%) and least present in Querdenken channels (23%). In general, characteristics of xenophobia (21%), exclusionism (15%), and nationalism (14%) were the most salient in Identitarian Movement’s communication, whereas populism was most present in QAnon’s communication (31%). While few Querdenken posts referenced either anti-democratic themes, nationalism, authoritarianism, or xenophobia (2%), the majority (22%) presents indications of populism. Although far-right indicators significantly decreased over time in the IM channels, indicating less radical communication in their public Telegram channels, the presence of far-right ideology significantly increased in Querdenken channels.
Conspiracy narratives
Overall, there were 1223 references to a specific conspiracy narrative in 950 posts (23%). The references were distributed as follows: 7% general, 10% far-right, and 9% COVID-19. Most conspiracy narratives were found in QAnon communication (33%), followed by IM (23%) and Querdenken (13%). QAnon referred to all categories of conspiracy narrative categories but mostly to general (15%). IM focused on far-right conspiracy narratives (20%), and Querdenken referred primarily to COVID–19-related conspiracy narratives (10%).
Overall, we found a significant positive linear trend indicating a general increase in the prevalence of conspiracy narratives; additionally, the non-linear trend was highly significant, indicating volatility (visible also in Figure 1).
Figure 1. Prevalence of Conspiracy Narratives over Time. Note. Raw values were plotted in thin gray lines with a bold black interpolated spline on top. The fitted smoothed dashed curve was estimated using a nonparametric loess regression (for visualization purposes). The gray areas surrounding the dashed line represent the 95% confidence interval.
Within each group, the linear increase was significant, indicating an increasing prevalence of conspiracy narratives over time. The lowest increase was found for QAnon and the steepest for Querdenken (Table 2). The visualization confirms this finding: Figure 1 shows the clearest trend of increasing conspiracy prevalence for the Querdenken discourse. The discourse of IM appears more volatile, possibly because of the high prevalence of far-right conspiracy narratives.
Anti-elitism
Overall, there were 2980 anti-elite expressions in 2137 posts (52%). QAnon channels expressed their discontent with the elite most frequently (61%), followed by Querdenken (50%) and IM (44%). For all three groups, most of the discontent with the elite was explained by expressions of criticism directed at politicians, ‘mainstream’ parties and government (QAnon 47%, Querdenken 43%, IM 29%), followed by criticism of journalism and public service broadcasting (QAnon 15%, Querdenken 12%, IM 12%). Further discontent was directed at political opponents and the left (IM 11%, QAnon 9%, Querdenken 2%) and science/scientists (QAnon 6%, Querdenken 6%, IM 1%). In addition, IM expressed criticism of (social media) companies relatively frequently (7%).
The trend statistics present a significant increase in the prevalence of anti-elitism. Group-specific analyses showed the highest growth over time in the communication of Querdenken. For IM and QAnon, the linear trend was also significant, but the increase was rather low. Figure 2 supports this, while the linear increase for QAnon and Identitarian Movement is hardly visible, the anti-elite sentiment in Querdenken communication is steeply increasing over time. Concerning the specific subcategories, the trend significantly increased across all of them.
Figure 2. Prevalence of Anti-Elitism over Time. Note. Raw values were plotted in thin gray lines with a bold black interpolated spline on top. The fitted smoothed dashed curve was estimated using a nonparametric loess regression (for visualization purposes). The gray areas surrounding the dashed line represent the 95% confidence interval.
Political participation and activism
There were 5207 calls for political participation and activism in 3251 posts (79%), making this category the most salient across all radicalization indicators and groups. The high salience was mostly explained by online activism (71%) and less by offline activism (13%) or online/offline activism (9%). Online activism was primarily explained by fringe (31%), social media engagement (24%) and (hyper-)partisan news use (21%). Offline participation mostly consisted of calls for participation in demonstrations (11% in all posts) and was especially present in Querdenken communication (26%); in online/offline activism, the evaluation of previous activism was most prevalent (5%). In Querdenken communication, almost every post (93%) contained one or several calls for participation or activism. However, this category was also prevalent among QAnon (73%) and IM channels (71%).
The trend statistics present a highly significant increase concerning the prevalence of participation and activism. The group-specific analysis showed that this trend was mostly explained by Querdenken communication, which had the highest increase over time. Additionally, IM communication indicated significantly increased activism. For QAnon, both the linear and non-linear trends were not significant. Calls for activism and participation were evenly distributed in QAnon communication but steeply increased in Querdenken communication at least until the end of 2020 (Figure 3). There was a significant increase in online and offline-related activism as well as in online/offline activism. Surprisingly, the increase in offline activism was mostly explained by IM and QAnon communication. For Querdenken, there was a non-significant decrease in offline activism, but their communication mostly explained the increase in online activism.
Figure 3. Prevalence of Calls for Participation and Activism over Time. Note. Raw values were plotted in thin gray lines with a bold black interpolated spline on top. The fitted smoothed dashed curve was estimated using a nonparametric loess regression (for visualization purposes). The gray areas surrounding the dashed line represent the 95% confidence interval.
Violence
Overall, there were 216 indications of pro-violent behavior in 130 posts (3%). The highest amount was found in IM communication (5%), followed by QAnon (3%) and Querdenken (1.5%). Violence-supporting posts were mostly explained by propensity (2%), approval (1%), and implicit calls for violence (1%). Across all items indicating support for violence, IM had the highest percentage of support for violence. Overall, violence rejection was far higher (10%) and was highest in IM (13%), followed by QAnon (12%), lowest among Querdenken (5%). Violence condemnation (6%), specifically against far-right actors (5%), ranked highest. While IM was most concerned with violence against the ingroup (8%), QAnon most frequently condemned violence in general.
The trend statistics show a mild but significant linear increase in violence-supporting content over the sampling period. Similarly, the rejection of violent behavior showed a positive linear trend and, in addition, a significant non-linear pattern. However, group-specific trends were only occasionally observed. Querdenken showed a non-linear trend in both violence support and rejection, indicating volatility, but also a low positive linear trend in violence rejection. Beyond that, only IM exhibited a significant non-linear trend in violence rejection. Figure 4 further illustrates that the theme of pro-violence behavior was present but, in concordance with our algorithm not picking up on any non-monotonic trend with respect to violence-supporting observations, was relatively evenly distributed throughout the analysis period.
Figure 4. Prevalence of Violence-Supporting Behavior over Time. Note. Raw values were plotted in thin gray lines with a bold black interpolated spline on top. The fitted smoothed dashed curve was estimated using a nonparametric loess regression (for visualization purposes). The gray areas surrounding the dashed line represent the 95% confidence interval.
Discussion
This study aimed to determine whether discourse in far-right Telegram channels indicates radicalization dynamics. A significant positive trend was observed for all indicators. Specifically, the prevalence of conspiracy narratives, anti-elitism, and calls for participation and activism increased over time, including support for violence but also the rejection of violence. Group-specific analyses revealed great differences regarding the prevalence and the changes over time of the different indicators.
Approximately every fifth post in the sample referred to at least one conspiracy narrative. It seems, this prevalence is highly dependent on the specific movement, as Hohlfeld et al. (2021) found that more than half of their sample of Telegram posts mentioned a conspiracy narrative. In our sample, QAnon communication presented the highest prevalence, which is not surprising considering that the movement was built on various conspiracy narratives. In comparison, IM communication had the highest prevalence of far-right ideology and far-right conspiracy narratives. For each movement, we observed a significant increase in the prevalence of conspiracy narratives, especially those related to COVID-19. Querdenken had the steepest increase for the prevalence of conspiracy narratives in general, while QAnon had the lowest, which can be attributed to the overall high prevalence of conspiracy-related communication in the QAnon channels. The high prevalence and increase in conspiracy narratives in Telegram communication can be considered worrisome since they can spread from fringe platforms to public discourse (Shahsavari et al., 2020).
Compared to all other indicators, anti-elite sentiment showed one of the strongest increases during the year, mainly due to a sharp increase of anti-elite sentiment in Querdenken communication. Anti-elitism can be considered an indicator for radicalization as it represents an increasing challenge to the legitimacy of the normative order (Abay Gaspar et al., 2020). This was strongest within Querdenken discourse, as anti-elite sentiment intensified throughout the year. This finding seemed transferable to the attitudes and behavior of Querdenken supporters: Grande et al. (2021) demonstrated that Querdenken supporters slowly moved from a diverse ideological spectrum to the far-right throughout 2020, increasingly supporting radical right parties and voicing discontent with the political order. Concerning the more extremist movements, QAnon and IM communication also presented a less steep but still significant increase in anti-elitism. One possible explanation for this could be that both movements had formed earlier and been officially considered extremist movements, so they had a higher initial prevalence of anti-elitism, whereas Querdenken formed throughout the investigation period. As such, QAnon channels had the highest prevalence of anti-elite expressions. For IM, the frequency of anti-elite sentiment was only slightly less and still constituted a large part of the discourse. While radicalization was only beginning in Querdenken channels, QAnon and IM had already established radicalized discourse, at least regarding anti-elite sentiment.
The amount of calls for political participation and activism increased the most among all indicators within the observation period, which was mostly explained by Querdenken communication. Querdenken had the steepest increase, while the increase was less pronounced in IM communication and non-significant for QAnon. Calls for participation was the most salient indicator across movements, suggesting the relevance of Telegram communication for mobilization and the willingness to disrupt the normative order. The subcategories illustrate that the majority of the calls referred to online activism rather than offline, highlighting the importance of online mobilization and activism. Similarly, Li et al. (2021) emphasized the increasing role and success of digital political participation or online activism, especially in radicalizing and mobilizing new individuals and protesting the current democratic order. In sum, the participation indicators in all three movements showed how important Telegram is for internal communication, news distribution and activism support. Therefore, Telegram appears to be more of a platform for the organization and mobilization of followers rather than an outreach tool for recruitment.
Violence was the least prevailing category in all posts, but its overall prevalence significantly increased over time. Advocacy of violence can be associated with more radicalized or even extremist tendencies and therefore be considered an indication of growing radicalization. As the most extreme manifestation of radicalization dynamics because of its intention of norm-deviating behavior among the categories studied, the comparatively low prevalence could correspond to the expectation that the more extreme the behavioral expression, the fewer individuals exhibit it. However, other explanations should be considered here. First, the low prevalence could be attributed to a relocation of the communication to closed channels/groups. Public discourse in 2020 was heavily concerned with communication on Telegram, as indicated by comprehensive news media coverage. This coverage changed the reach and attention for some actors and groups on Telegram (Schulze, 2021) and showed the public’s awareness of far-right communication on Telegram, potentially changing the communication behavior of far-right actors (e.g., refraining from transgressive behavior such as incitement to violence to avoid deletions). Additionally, vast deplatforming activities in summer and fall 2020 and the inaccessibility of some Telegram channels from mobile phones (whose operators restricted access) could have impacted far-right communication on public Telegram channels.
Second, expressions of support for violence online are not necessarily directly linked to violent behavior offline. Extremists who turn to violent behavior are not necessarily those who publish the most violent content online (McIlroy-Young and Anderson, 2019), and violent extremists post less online than non-violent extremists (Scrivens et al., 2021). This last point, in turn, puts the significance of violence as an indicator for radicalization dynamics in online discourses into perspective, even though it is the most extreme form of radicalization. Querdenken and IM usually depict themselves as peaceful movements that strictly oppose violent behavior. Our analysis showed that this is not reflected in their online communication: Their position towards violence can be regarded at least as ambiguous since both movements voiced support for violent behavior in their Telegram communication. This trend was also confirmed for Querdenken activism in general (Hunger et al., 2021). Yet, it must be recognized that rejection of violence is, compared to violence-supporting behavior, more prevalent in our sample. In general, we observed an increase in the rejection of violent behavior, mainly driven by the Querdenken movement, which seemed to develop in parallel with expressions that support violence.
Our results indicate radicalization dynamics within the discourse of the three studied movements. However, the change within online communication does not necessarily translate into changes in offline behavior. The results indicate developments that need to be further observed and studied. While we cannot infer a direct effect of the studied indicators, we can presume that a movement whose communication changes drastically is more likely to become active beyond its online networks. Offline events with increasing levels of aggressiveness and violent action in COVID–19-related demonstrations indicate that the changes observed in online communication were also present offline.
Limitations
As a single platform study focusing on Telegram, it is not possible to apply the results to the general online communication of these movements. All three movements are highly active online on other Telegram channels or groups – especially closed ones that allow more extremist communication – and across different platforms, as well as offline when, for example, organizing activities or participating in demonstrations. Therefore, the increasing prevalence of radicalization indicators cannot be considered evidence of radicalization throughout the movements. Furthermore, while we were able to estimate the amount of deleted content, we were unable to determine what kind of content was deleted. Additionally, the indicators of radicalization dynamics only serve as proxies for radicalization dynamics. Since we only study the supply side in terms of content published online, we are unable to make any conclusions about the perception of specific posts or the discourse overall. Also, focusing on one specific country – Germany – we are unable to address the influence of macro factors, such as sociocultural or economic specificities, on radicalization dynamics in online environments.
Conclusion
This paper explored possible indicators of radicalization dynamics in far-right fringe platform communication. We found strong indications that the discourse in Telegram became more radicalized from March 2020 until February 2021. The degree of this trend varied across indicators and movements. The greatest changes were observed within the Querdenken channels, whose communication presented the steepest increase in the prevalence of conspiracy narratives, anti-elitism and calls for activism. Communication in more established extremist movements presented less radicalization compared to a movement in its infancy. However, the prevalence of these indicators had the highest saliency in QAnon communication, and IM was most supportive of violence.
Particularly noteworthy, the prevalence of support for violence increased over the study period. This increase, together with the even greater increase in the other indicators studied, such as conspiracy narratives, anti-elitism, and calls for activism and taking into account offline (protest) events, clearly supports the argument of incremental radicalization dynamics. While support for violence can be considered the most obvious indicator of radicalization/extremism, it is likewise the first indicator to adapt in strategic communication, given deplatforming measures and mobile phone companies restricting access to certain Telegram channels. Extremist actors are aware of external observations of their communication in public Telegram channels and, in consequence, shift at least parts of their communication into clandestine areas of the Internet. This makes the existence of such, presumably even more radical and violence-supporting communication (not considered in this study) very likely. The group-specific trends in our study differentiate but also underpin the perspective on the current overall trend, which coherently points to a vigorous intensification of radicalization dynamics in all the movements we examined.
Overall, we suggest that our approach to analyzing indicators of a radicalization process by measuring the changes in the prevalence of certain themes in online environments is useful to monitor radical/extremist movements and their (strategic) communication behavior, especially its adaptation. The movement-specific differences in the Telegram communication reflect well the general differences of the three groups: QAnon, Identitarian Movement, and Querdenken. This supports the appropriateness of our method to study the changes in the movements' communication. However, our analyses show that it is crucial to not just focus on one single indicator but consider longitudinal changes across several indicators, ideally comparing different movements. To further address and reduce the conceptual vagueness of online radicalization, we encourage future studies to use this approach as a starting point to consider in greater depth how radicalization dynamics unfold based on the analysis of language, user behavior, and (propaganda) material online.
Considering the fact that this study presents a first suggestion to operationalize indicators of radicalization dynamics in discourse, numerous possibilities of following research are conceivable. Of course, it will be interesting to expand the scope of this study to (1) include more indicators such as, for example, deceptive information in the form of propaganda or mis-/disinformation, (2) increase the number of channels and groups, as well as far-right accounts that are not linked to a specific movement, (3) compare our results to other forms of extremism, (4) account for the effects of specific events concerning the prevalence of specific indicators (e.g., Storming of Reichstagssteps, Terrorist Attacks), and (5) compare these Telegram specific results to other platforms.
Funding
The authors disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This study was supported by grants from the German Federal Ministry of Education and Research within the framework of the program "Research for Civil Security" of the Federal Government and the German Federal Ministry of the Interior. (grant no. MOTRA-13N15223).
ORCID iD
Heidi Schulze https://orcid.org/0000-0003-0079-9169
Diana Rieger https://orcid.org/0000-0002-2417-0480
Simon Greipl https://orcid.org/0000-0002-5652-8889
Notes
1.
On a theoretical basis, research distinguishes between (1) the radical right, which recognizes democracy as a functioning form of government but seeks to replace the elite, and (2) the extreme right, which seeks to abolish democracy and considers violence a proven means of enforcing its own political ideology (Berntzen, 2019; Bjørgo and Ravndal, 2019). However, due to the volatility of the supporters of such movements, it is practically impossible to study the movements separately. The term farright is employed to subsume all those radical and extremist movements and groups that view the people and state as a single entity and foreigners as a threat to the community (Bjørgo and Ravndal, 2019). Thus, this study used ‘far right’ as an umbrella term.
2.
Rather than resorting directly to the theoretical concept of radicalization, the term radicalization dynamics is used to be transparent about both the complexity of different types of processes involved in radicalization, and the fact that we examined relative changes within indicators of (online-)radicalization (rather than stages, for example, along a process continuum).
3.
Referring to the definition by Abay Gaspar et al. (2020), conspiracy narratives and anti-elitism are more closely tied to the ‘challenge to the legitimacy of a normative order’ while political activism and support for violence relate to behavioral intentions and thereby to an increased ‘willingness to fight the institutional structure of this order’ (p. 5).
4.
In addition, at least two more terms are currently employed despite referring to the same platforms or studying similar phenomena: (1) Zeng and Schäfer (2021: 1) introduce the term dark platforms to refer to platforms ‘that are less regulated and moderated, hence can be used for hosting content and content creators that may not be tolerated by their more mainstream counterparts’. (2) Frequently, fringe platforms are also referred to as alternative social media (e.g., Rogers, 2020), indicating that they function as an alternative to traditional social media platforms. All three terms (fringe, dark, and alternative) have in common that they describe ‘non-mainstream’ platforms that potentially foster extremist networks and radicalization. We opted for the term fringe to emphasize the aspect of political fringeness and how platform architectures afford radicalism/extremism. However, it should be noted that the scholarship studying such platforms is not yet very reflective regarding the interchangeability of the terms or a conceptualization of their differences.
5.
OSF Repository: https://osf.io/5edph/
References
Abay Gaspar H, Daase C, Deitelhoff N, et al. (2020) Radicalization and political violence – challenges of conceptualizing and researching origins, processes and politics of illiberal beliefs. International Journal of Conflict and Violence 14(2): 1–19.
Agapov PV, Smyslova VN, Krasnova KA, et al. (2020) Radicalization—protest activity—extremism: modern paradigms and manifestations. In: 2nd International Conference on Pedagogy, Communication and Sociology (ICPCS 2020), Bangkok, Thailand, pp. 480–484.
Ahmed W, Vidal-Alaball J, Downing J, et al. (2020) COVID-19 and the 5G conspiracy theory: social network analysis of Twitter data. Journal of Medical Internet Research 22(5): 1–9. Crossref. Web of Science.
Aslanidis P (2018) Measuring populist discourse with semantic text analysis: an application on grassroots populist mobilization. Quality & Quantity 52(3): 1241–1263. Crossref. Web of Science.
Barker T (2020) Germany Is Losing the Fight against QAnon. Available at: https://www.aspeninstitute.de/wp-content/uploads/COVID-19-Pandemic-Conspiracy-Theories-Are-Taking-Over-German-Democracy.pdf (accessed 02 February 2021).
Baugut P, Neumann K (2020) Online news media and propaganda influence on radicalized individuals: findings from interviews with Islamist prisoners and former Islamists. New Media & Society 22(8): 1437–1461. Crossref. Web of Science.
Berntzen LE (2019) Liberal Roots of Far Right Activism. London: Routledge. Crossref.
Bilewicz M, Soral W (2020) Hate speech epidemic. The dynamic effects of derogatory language on intergroup relations and political radicalization. Political Psychology 41(S1): 3–33. Crossref.
Bjørgo T, Aasland Ravndal J (2019) Extreme-Right Violence and Terrorism: Concepts, Patterns, and Responses. Available at: https://icct.nl/app/uploads/2019/09/Extreme-Right-Violence-and-Terrorism-Concepts-Patterns-and-Responses-4.pdf (accessed 1 September 2021).
Boberg S, Quandt T, Schatto-Eckrodt T, et al. (2020) Pandemic Populism: Facebook Pages of Alternative News Media and the Corona Crisis ‐ A Computational Content Analysis. Available at: http://arxiv.org/pdf/2004.02566v3 (accessed 1 September 2021).
Carter E (2018) Right-wing extremism/radicalism: reconstructing the concept. Journal of Political Ideologies 23(2): 157–182. Crossref. Web of Science.
Casemajor N, Couture S, Delfin M, et al. (2015) Non-participation in digital media: toward a framework of mediated political action. Media, Culture & Society 37(6): 850–866. Crossref. Web of Science.
Davies G, Wu E, Frank R (2021) A witch’s brew of grievances: the potential effects of COVID-19 on radicalization to violent extremism. Studies in Conflict & Terrorism. Epub ahead of print 10 May 2021. Crossref. PubMed.
Dittrich M, Grandjean A, Jäger L, et al. (2020) QAnon in Deutschland. de:hate report #01. [QAnon in Germany. de:hate report #01] Report. Germany: Amadeu Antonio Stiftung.
Douglas KM, Uscinski JE, Sutton RM, et al. (2019) Understanding conspiracy theories. Political Psychology 40(S1): 3–35. Crossref. Web of Science.
Dzhekova R, Stoynova N, Kojouharov A, et al. (2016) Understanding radicalization. Review of Literature. Sofia: Center for the Study of Democracy.
Edgerly S, Vraga EK (2020) Deciding what’s news: news-ness as an audience concept for the hybrid media environment. Journalism & Mass Communication Quarterly 97(2): 416–434. Crossref. Web of Science.
Ernst N, Engesser S, Esser F (2017) Bipolar populism? The use of anti-elitism and people-centrism by Swiss parties on social media. Swiss Political Science Review 23(3): 253–261. Crossref.
Feng GC (2014) Intercoder reliability indices: disuse, misuse, and abuse. Quality & Quantity 48(3): 1803–1815. Crossref.
Fielitz M, Schwarz K (2020) Hate Not Found?! Deplatforming the Far Right and its Consequences. Available at: https://www.idz-jena.de/fileadmin//user_upload/Hate_not_found/IDZ_Research_Report_Hate_not_Found.pdf (accessed 31 August 2021).
Frischlich L, Schatto-Eckrodt T, Völker J (2022) Rückzug in den Schatten? Die Verlagerung digitaler Foren zwischen Fringe Communities und “Dark Social” und ihre Implikationen für die Extremismusprävention [Retreat into the shadows? The shift of digital forums between fringe communities and ‘dark social’ and its implications for the prevention of extremism]. CoRE-NRW Kurzgutachen Nr 4. Available at: https://www.bicc.de/uploads/tx_bicctools/CoRE_kurzGutachten_Schatten_220119.pdf.
Funke M, Schularick M, Trebesch C (2016) Going to extremes: politics after financial crises, 1870–2014. European Economic Review 88: 227–260. Crossref. Web of Science.
Garry A, Walther S, Mohamed R, et al. (2021) QAnon conspiracy theory: examining its evolution and mechanisms of radicalization. Journal for Deradicalization Spring 2021(26): 152–216.
Gaudette T, Scrivens R, Venkatesh V (2020) The role of the internet in facilitating violent extremism: insights from former right-wing extremists. Terrorism and Political Violence. Epub ahead of print 16 July 2021. Crossref.
Gerstenfeld PB, Grant DR, Chiang C-P (2003) Hate online: a content analysis of extremist internet sites. Analyses of Social Issues and Public Policy 3(1): 29–44. Crossref.
Gidron N, Hall PA (2020) Populism as a problem of social integration. Comparative Political Studies 53(7): 1027–1059. Crossref. Web of Science.
Goertzel T (1994) Belief in conspiracy theories. Political Psychology 15(4): 731–742. Crossref. Web of Science.
Grande E, Hutter S, Hunger S, et al. (2021) Alles Covidioten? Politische Potenziale des Corona-Protests in Deutschland. [All Covidiots? Political Potentials of the Corona Protest in Germany]. WZB Discussion Paper (ZZ 2021-601).
Harlow S, Harp D (2012) Collective action on the web. Information, Communication & Society 15(2): 196–216. Crossref. Web of Science.
Hawkins KA, Carlin RE, Littvay L, Kaltwasser CR, et al. (2018) The Ideational Approach to Populism: Concept, Theory, and Analysis. London/New York: Routledge. Crossref.
Hine GE, Onaolapo J, Cristofaro ED, et al. (2017) Kek, cucks, and god emperor trump: a measurement study of 4chan’s politically incorrect forum and its effects on the web. Proceedings of the International AAAI Conference on Web and Social Media 11(1): 92–101. Crossref.
Hohlfeld R, Bauerfeind F, Braglia I, et al. (2021) Communicating COVID-19 against the Backdrop of Conspiracy Ideologies: How Public Figures Discuss The Matter On Facebook and Telegram. Report. Germany: RatSWD.
Holzer B (2021) Zwischen Protest und Parodie: Strukturen der »Querdenken«-Kommunikation auf Telegram (und anderswo) [Between Protest and Parody: Structures of “Querdenken” Communication on Telegram (and Elsewhere)]. In: Reichardt S (ed) Die Misstrauensgemeinschaft der »Querdenker« Die Corona-Proteste aus kultur- und sozialwissenschaftlicher Perspektive [The distrust community of “Querdenker” The Corona protests from a cultural and social science perspective.]. Frankfurt/New York: Campus Verlag, 125–157.
Hunger S, Völker T, Saldivia D (2021) Der Verlust der Vielfalt. Die Corona-Proteste in Deutschland werden durch eine radikale Mehrheit geprägt [Loss of diversity. The Corona protests in Germany are characterized by a radical majority] WZB Notifications (No. 127). WZB Berlin.
Imhoff R, Lamberty P (2020) A bioweapon or a hoax? The link between distinct conspiracy beliefs about the coronavirus disease (COVID-19) outbreak and pandemic behavior. Social Psychological and Personality Science 11(8): 1110–1118. Crossref. PubMed. Web of Science.
Jasser G, McSwiney J, Pertwee E, et al. (2021) ‘Welcome to# GabFam’: far-right virtual community on Gab. New Media & Society. Epub ahead of print 28 June 2021. Crossref. PubMed.
Lamberty P (2020a) Verschwörungsmythen Als Radikalisierungsbeschleuniger: Eine Psychologische Betrachtung. [Conspiracy Myths as Radicalization Accelerators: A Psychological Review]. Available at: http://library.fes.de/pdf-files/dialog/16197-20200529.pdf (accessed 31 August 2021).
Leader Maynard J, Benesch S (2016) Dangerous speech and dangerous ideology: an integrated model for monitoring and prevention. Genocide Studies and Prevention 9(3): 70–95. Crossref.
Li Y, Bernard JG, Luczak-Roesch M (2021) Beyond clicktivism: what makes digitally native activism effective? An exploration of the sleeping giants movement. Social Media + Society. Epub ahead of print 04 August 2021. Crossref. PubMed.
Lonami (2019) Telethon Revision 219b4ecb. Available at: https://docs.telethon.dev/en/latest (accessed 31 August 2021).
Lyubchich V, Gel YR, El-Shaarawi A (2013). “On detecting non-monotonic trends in environmental time series: a fusion of local regression and bootstrap”. Environmetrics 24(4): 209–226. Crossref.
Lyubchich V, Gel YR, Brenning A, et al. (2021) Funtimes: Functions for Time Series Analysis. R package version 8.1. Available at: https://CRAN.R-project.org/package=funtimes (accessed 31 August 2021).
Mahl D, Zeng J, Schäfer MS (2021) From “Nasa lies” to “reptilian eyes”: mapping communication about 10 conspiracy theories, their communities, and main propagators on Twitter. Social Media + Society. Epub ahead of print 12 May 2021. Crossref. PubMed.
McGregor I, Prentice M, Nash K (2013) Anxious uncertainty and reactive approach motivation (RAM) for religious, idealistic, and lifestyle extremes. Journal of Social Issues 69(3): 537–563. Crossref.
McIlroy-Young R, Anderson A (2019) From “welcome new gabbers” to the pittsburgh synagogue shooting: the evolution of gab. In Proceedings of the International AAAI Conference on Web and Social Media 13: 651–654.
Mølmen GN, Ravndal JA (2021). Mechanisms of online radicalization: how the internet affects the radicalization of extreme-right lone actor terrorists. Behavioral Sciences of Terrorism and Political Aggression. Epub ahead of print 30 October 2021. Crossref.
Mudde C (2002) The Ideology of the Extreme Right. Manchester: Manchester University Press. Crossref.
Mudde C, Kaltwasser CR (2017) Populism: A Very Short Introduction. Oxford: Oxford University Press. Crossref.
Noguchi K, Gel YR, Duguay CR (2011) Bootstrap-based tests for trends in hydrological time series, with application to ice phenology data. Journal of Hydrology 410(3–4): 150–161. Crossref.
Obaidi M, Kunst J, Ozer S, et al. (2021) The “great replacement” conspiracy: how the perceived ousting of Whites can evoke violent extremism and Islamophobia. Group Processes & Intergroup Relations. Epub ahead of print 06 August 2021. Crossref.
Odağ Ö, Leiser A, Boehnke K (2019) Reviewing the role of the internet in radicalization processes. Journal for Deradicalization 21/2019(Winter 2019/21): 261–300.
Olteanu A, Castillo C, Boy J, et al. (2018) The Effect of Extremist Violence on Hateful Speech Online. Available at: https://ojs.aaai.org/index.php/ICWSM/article/view/15040/14890 (accessed 1 September 2021).
Peeters S, Hagen S (2018) 4CAT: Capture and Analysis Toolkit Computer Software. Version 1.0.
Pickel G, Pickel S, Yendell A (2020) Zersetzungspotenziale einer demokratischen politischen Kultur: Verschwörungstheorien und erodierender gesellschaftlicher Zusammenhalt? [Decomposition potentials of a democratic political culture: conspiracy theories and eroding social cohesion?]. In: Decker O, Brähler E (eds) Autoritäre Dynamiken: Alte Ressentiments - Neue Radikalität/Leipziger Autoritarismus Studie 2020 [Authoritarian Dynamics: Old Resentments - New Radicality/Leipzig Authoritarianism Study 2020]. Psychosozial-Verlag, 89–118. Crossref.
Popper K (2003) Die offene Gesellschaft und ihre Feinde. Band II: Falsche Propheten: Hegel, Marx und die Folgen [The Open Society and its Enemies. Volume II: False Prophets: Hegel, Marx and the Consequences]. Mohr Siebeck.
Quarfoot D, Levine RA (2016). How robust are multirater interrater reliability indices to changes in frequency distribution? The American Statistician 70(4): 373–384. Crossref. Web of Science.
Reichardt S (ed) (2021) Die Misstrauensgemeinschaft der »Querdenker« Die Corona-Proteste aus kultur- und sozialwissenschaftlicher Perspektive [The Distrustful Community of “Querdenker” The Corona Protests From a Cultural and Social Science Perspective]. Frankfurt/New York: Campus Verlag.
Riebe T, Pätsch K, Kaufhold MA, et al. (2018) From conspiracies to insults: a case study of radicalization in social media discourse. In: Dachselt R, Weber G (eds) Mensch und Computer 2018 - Workshopband [Man and Computer 2018 - Workshop Tape]. Bonn: Gesellschaft für Informatik e.V., 595–603.
Rieger D, Frischlich L, Bente G (2017) Propaganda in an insecure, unstructured world: how psychological uncertainty and authoritarian attitudes shape the evaluation of right-wing extremist internet propaganda. Journal for Deradicalization 2017(Spring Issue 10): 203–229.
Rogers R (2020) Deplatforming: following extreme internet celebrities to Telegram and alternative social media. European Journal of Communication 35(3): 213–229. Crossref. Web of Science.
Rothut S, Schulze H, Hohner J, et al. (2022) Radikalisierung im Internet – Ein systematischer Überblick über Forschungsstand, Wirkungsebenen sowie Implikationen für Wissenschaft und Praxis. [Radicalization Online - A Systematic Overview of the State of Research, Effect Dimensions, and Implications for Researcher and Practice]. CoRE-NRW. Available at: https://www.bicc.de/uploads/tx_bicctools/CoRE_KurzGutachten_5.pdf (accessed 25 April 2021).
Schulze H (2021) Zur Bedeutung von Dark Social & Deplatforming. Eine quantitative Exploration der deutschsprachigen Rechtsaußenszene auf Telegram. [Dark Social & Deplatforming. A quantitative exploration of the German-speaking far-right scene on Telegram.]. Zeitschrift für Semiotik 42(2–4): 61–86.
Schulze H, Hohner J, Rieger D (2022) Soziale Medien und Radikalisierung [Social Media and Radicalization]. In: L Rothenberger, J Krause, J Jost, K Frankenthal (eds). Terrorismusforschung - Interdisziplinäres Handbuch für Wissenschaft und Praxis [Handbook Terrorism Research]. Nomos, In press.
Scrivens R (2020). Exploring radical right-wing posting behaviors online. Deviant Behavior 42(2): 1–15.
Scrivens R, Wojciechowski TW, Freilich JD, et al. (2021) Comparing the online posting behaviors of violent and non-violent right-wing extremists. Terrorism and Political Violence. Epub ahead of print 08 March 2021. Crossref.
Shahsavari S, Holur P, Wang T, et al. (2020) Conspiracy in the time of corona: automatic detection of emerging COVID-19 conspiracy theories in social media and the news. Journal of Computational Social Science 3(2): 279–317. Crossref. PubMed. Web of Science.
Starbird K (2017) Examining the alternative media ecosystem through the production of alternative narratives of mass shooting events on Twitter. Proceedings of the International AAAI Conference on Web and Social Media 11(1): 230–239. Crossref.
Stieger S, Gumhalter N, Tran US, et al. (2013) Girl in the cellar: a repeated cross-sectional investigation of belief in conspiracy theories about the kidnapping of Natascha Kampusch. Frontiers in Psychology 4: 297. Crossref. PubMed. Web of Science.
Struck J, Kraus B, Görgen T (2017) “Ladet endlich die Gewehre durch, oder müssen wir alles selber machen, ich bin dabei”: Analytische Zugriffe auf Internet und soziale Medien als Orte extremistischer Straftatenaufrufe [“Load the rifles at last, or do we have to do everything ourselves, i’m with you”: analytical access to the internet and social media as sites of extremist calls to crime]. Neue Kriminalpolitik 29(4): 398–407.
Taddicken M, Schmidt JH (2017) Entwicklung und Verbreitung sozialer Medien [Development and dissemination of social media]. In: Schmidt JH, Taddicken M (eds) Handbuch Soziale Medien [Social Media Handbook]. Wiesbaden: Springer VS, 1–20. Crossref.
Telegram FZ-LLC (2020) Telegram APIs. Available at: https://core.telegram.org/(accessed 31 August 2021).
Theocharis Y, Moor J, Deth JW (2021) Digitally networked participation and lifestyle politics as new modes of political participation. Policy & Internet 13(1): 30–53. Crossref. Web of Science.
Unkel J (2021) tidycomm: Data Modification and Analysis for Communication Research. R package version 0.1.0. Available at: https://CRAN.R-project.org/package=tidycomm (accessed 31 August 2021).
Urman A, Katz S (2020) What they do in the shadows: examining the far-right networks on Telegram. Information, Communication & Society. Epub ahead of print 20 August 2020. Crossref.
Van Dijck J, de Winkel T, Schäfer MT (2021) Deplatformization and the governance of the platform ecosystem. New Media & Society. Epub ahead of print 23 September 2020. Crossref. PubMed.
Van Prooijen JW, Krouwel APM, Pollet TV (2015) Political extremism predicts belief in conspiracy theories. Social Psychological and Personality Science 6(5): 570–578. Crossref. Web of Science.
Vollmer B, Karakayali S (2018) The volatility of the discourse on refugees in Germany. Journal of Immigrant & Refugee Studies 16(1–2): 118–139. Crossref. Web of Science.
Walther S, McCoy A (2021) US extremism on Telegram: fueling disinformation, conspiracy theories, and accelerationism. Perspectives on Terrorism 15(2): 100–124.
Whitson JA, Galinsky AD (2008) Lacking control increases illusory pattern perception. Science (New York, N.Y.) 322(5898): 115–117. Crossref. PubMed. Web of Science.
Wickham H, Averick M, Bryan J, et al. (2019) Welcome to the tidyverse. Journal of Open Source Software 4(43): 1686. Crossref.
Wojcieszak M (2009) “Carrying online participation offline”-mobilization by radical online groups and politically dissimilar offline ties. Journal of Communication 59(3): 564–586. Crossref. Web of Science.
Zeng J, Schäfer MS (2021) Conceptualizing “dark platforms”. Covid-19-related conspiracy theories on 8kun and Gab. Digital Journalism 1–23: 1321–1343. Crossref.
Author Biographies
Heidi Schulze is a researcher at the Department of Media and Communication at LMU Munich. At LMU, she is part of the research lab of Prof. Dr. Rieger and studies online radicalization dynamics within a large-scale research project. In her research, she focuses on radical/extremist (group) communication in (alternative) social media platforms and fringe communities, as well as characteristics and audiences of hyperpartisan news websites.
Julian Hohner is a research associate at the research lab of Prof. Dr. Rieger (IfKW, LMU Munich). His research interests lie in the area of computational social science. His Ph.D. project deals with developing methods for detecting radicalization and extremism in digital environments.
Simon Greipl is a research associate in Prof. Dr. Rieger's team at the Department of Media and Communication at the University of Munich (LMU). As part of the MOTRA project, funded by the German Ministry for Education and Research (BMBF), he is working on the indication of radicalization dynamics in online environments. His special research interest is the investigation of radicalization phenomena in the context of gaming and its communities.
Max Girgnhuber is a graduate student in the Master’s Program Communication Science at LMU Munich and a student assistant at the research lab of Prof. Dr. Rieger.
Isabell Desta is a graduate student in the Master’s Program Communication Science at LMU Munich and a student assistant at the research lab of Prof. Dr. Rieger.
Diana Rieger is a full professor at the Department of Media and Communication at LMU Munich. Her research focuses on extremist online communication and which characteristics can contribute to radicalization dynamics on the Internet. In addition, her research focuses on deradicalization and prevention measures.